# Robotics Vision & Calibration Suite

A modular, production-grade Python toolkit for robotics calibration, vision, 3D point cloud processing, and automated pose/trajectory collection.

**Supports:**

* Robot high-level API (move, home, state, RPC)
* RealSense 3D camera management
* Automated Charuco and hand-eye calibration (OpenCV)
* 3D point cloud generation, transformation, and visualization
* CLI tools for pose recording, trajectory execution, calibration, camera debug, and cloud ops
* Flexible, extensible logger with JSON/file support

---

## ðŸ“‚ Project Structure (Navigator)

```
project-root/
â”‚
â”œâ”€â”€ calibration/          # Calibration algorithms & workflows
â”‚   â”œâ”€â”€ charuco.py              # Charuco board calibration helpers
â”‚   â”œâ”€â”€ handeye.py              # Hand-eye calibration helpers
â”‚   â”œâ”€â”€ pose_loader.py          # Load robot poses from JSON
â”‚   â”œâ”€â”€ workflows.py            # High-level calibration routines
â”‚   â””â”€â”€ README.md               # Package overview
â”‚
â”œâ”€â”€ robot/                # Robot API & workflows
â”‚   â”œâ”€â”€ controller.py          # Main control class
â”‚   â”œâ”€â”€ workflows.py          # Pose recorder and path runner
â”‚   â”œâ”€â”€ marker.py             # Simple marker utilities
â”‚   â”œâ”€â”€ Robot.py              # Cython RPC bindings
â”‚   â””â”€â”€ README.md             # Package overview
â”‚
â”œâ”€â”€ utils/                # Common utilities
â”‚   â”œâ”€â”€ config.py         # Config loading/abstraction
â”‚   â”œâ”€â”€ logger.py         # Centralized, JSON-capable logger
â”‚   â”œâ”€â”€ io.py             # Camera calibration I/O
â”‚   â”œâ”€â”€ geometry.py       # Math helpers
â”‚   â””â”€â”€ README.md         # Package overview
â”‚
â”œâ”€â”€ vision/               # Vision, cloud, and camera utils
â”‚   â”œâ”€â”€ opencv_utils.py        # OpenCV helper class
â”‚   â”œâ”€â”€ realsense.py           # RealSense camera wrapper
â”‚   â”œâ”€â”€ pointcloud.py          # PointCloudGenerator class and utilities
â”‚   â”œâ”€â”€ tools.py               # Camera and cloud helper routines
â”‚   â”œâ”€â”€ transform.py           # 3D transformation utilities
â”‚   â””â”€â”€ README.md              # Explanation of transform chain
â”‚
â”œâ”€â”€ config.yaml           # Main configuration file
â”œâ”€â”€ pyproject.toml        # Project metadata & dependencies
â””â”€â”€ README.md             # You are here
```

---

## ðŸš€ Quickstart

### 1. Clone & Install

```bash
git clone ...
cd project-root
uv venv .venv -p 3.11
source .venv/bin/activate
uv pip install -e .
```

### 2. Configure

Edit `config.yaml` for your robot/camera IP, tool, velocity, logging, and point cloud settings.

### 3. Run CLI Tools
CLI modules are thin wrappers calling workflow helpers under
`calibration/`, `robot/`, and `vision/`.

* Save a pose:

  ```bash
  poses-saver
  ```
* Run a trajectory from file:

  ```bash
  path-runner
  ```
* Calibrate camera (Charuco):

  ```bash
  charuco-calib
  ```
* Capture point cloud:

  ```bash
  pointcloud-capture --output clouds/cloud.ply
  ```
* Restart robot connection:

  ```bash
  robot-restart
  ```

### 4. Build & Install

Use `pyproject.toml` together with [uv](https://github.com/astral-sh/uv) for reproducible environments/builds:

```bash
uv venv .venv -p 3.12
uv pip install -e .
```

All dependencies are defined in `pyproject.toml`. To create a traditional
`requirements.txt` snapshot run `uv pip freeze > requirements.txt`.

---

## ðŸ“‘ Documentation

### Configuration (`config.yaml`)

* `robot:` â€” IP, tool/user frame, velocity, emergency delay
* `vision:` â€” RealSense stream parameters, cloud parameters
* `logging:` â€” log directory, level, JSON output
* `cloud:` â€” point cloud settings (output dir)
* `cloud_pipeline:` â€” dataset paths, depth scale, ROI limits
* `gpt:` â€” API keys and endpoints for path generation
* Defaults for paths, robot IP, and Charuco dictionary mapping are defined in `utils/constants.py`

### Logger (`utils/logger.py`)

* Central logger: file/console, JSON/text, auto-timestamped logs
* Decorators for function/exception logging
* Use in all modules:

  ```python
  from utils.logger import Logger
  logger = Logger.get_logger("my.module", json_format=True)
  ```

### Robot API (`robot/controller.py`)

* `RobotController` â€” High-level API: connect, move, record, return home, shutdown
* Uses config + logger

### Calibration Modules

* `CharucoCalibrator` â€” Board-based camera calibration (OpenCV ArUco)
* `HandEyeCalibrator` â€” Tsai/Daniilidis methods, modular savers for results

### Vision

* `RealSenseCamera` â€” Start/stop, get frames, intrinsics, depth scale
* `opencv_utils.py` â€” draw\_text, normalize\_depth, apply\_colormap

### 3D Point Cloud Modules

* `pointcloud.py` â€” Depth to point cloud conversion, save/load (PLY, XYZ, npz), filtering, merging
* `transform.py` â€” Rigid transformations between camera/robot/world coordinates (uses calibration, see vision/README.md)
* CLI scripts provided via entry points (`pointcloud-capture`, `pointcloud-transform`, `pointcloud-view`)

**See [vision/README.md](./vision/README.md) for detailed usage, coordinate system details, and all math for 3D transforms.**

**Typical workflow:**

1. Capture depth + color â†’ generate cloud (`pointcloud-capture`)
2. (Optional) Filter, merge, or transform clouds (robot <-> camera <-> world)
3. Save or visualize result (`pointcloud-view`)

### CLI Tools

Entry points defined in `pyproject.toml` expose the common workflows:
`poses-saver`, `path-runner`, `charuco-calib`, etc. The underlying logic lives
within the respective packages.

### Extensibility/Testing
* Run tests with `pytest`.

* Logger, config, robot, camera: all support dependency injection for unit tests or swapping implementations.
* Add new data savers, control strategies, vision pipelines, or point cloud processors with minimal edits.

---

## ðŸ§° Troubleshooting

* All logs are stored in `logs/` (JSON if enabled)
* Use `logging.level` and `logging.json` in config.yaml to control verbosity/format
* CLI tools print progress, errors, and file names
* For RealSense errors: check camera connection, permissions, drivers, and stream config
* For robot errors: verify IP, cable, firewall, and physical enable state
* For point cloud issues: check calibration files, cloud parameters, and output formats

---
